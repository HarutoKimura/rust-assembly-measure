# Performance Measurement for Cryptographic Assembly Code

This Rust project measures and compares the performance of cryptographic field arithmetic functions implemented in assembly code. It specifically evaluates implementations generated by different backends or sources, comparing assembly in GAS format, NASM format, and code generated by the CryptOpt tool.

The goal is to benchmark these assembly variants across various cryptographic curve implementations derived from both Fiat-Rust and Fiat-C projects.

## Constant-Time Validation Support

The project includes comprehensive constant-time validation through two complementary approaches:

### 1. DUDECT - Statistical Validation
- **Method**: Statistical analysis of timing measurements
- **Approach**: Compares execution times between fixed and random inputs
- **Benefits**: Fast, doesn't require complex setup
- **Limitations**: Provides statistical confidence, not mathematical proof

### 2. BINSEC - Formal Verification
- **Method**: Symbolic execution and formal methods
- **Approach**: Mathematically proves absence of timing leaks
- **Benefits**: Provides formal guarantees, identifies exact leak locations
- **Limitations**: Slower, may timeout on complex functions

### Running Constant-Time Validation

```bash
# Statistical validation with DUDECT only
CARGO_DUDECT_VALIDATE=1 cargo build

# Formal verification with BINSEC only
CARGO_BINSEC_VALIDATE=1 cargo build

# Run both validations (recommended)
CARGO_DUDECT_VALIDATE=1 CARGO_BINSEC_VALIDATE=1 cargo build
```

### Setup Instructions
- **DUDECT**: No additional setup required (included in the project)
- **BINSEC**: Requires OCaml and dependencies. See [BINSEC_SETUP.md](BINSEC_SETUP.md) for installation
- **Full Documentation**: See [BINSEC_INTEGRATION_DOCUMENTATION.md](BINSEC_INTEGRATION_DOCUMENTATION.md) for detailed implementation information

## Features

- Benchmarks multiplication (`mul`) and squaring (`square`) operations (where available).
- Supports implementations derived from both **Fiat-Rust** and **Fiat-C**.
- Compares three assembly variants for each function:
    - **GAS format** (typically output by LLVM)
    - **NASM format** (converted from GAS)
    - **CryptOpt** (optimized NASM format)
- Measures performance using CPU cycle counts (`rdtsc`).
- Employs median-of-medians approach over multiple runs for robust results.
- Includes basic correctness checks by comparing outputs (though not the primary focus).
- Supports benchmarking for the following curves/implementations:
    - Curve25519 (Fiat-Rust)
    - Curve25519-Dalek (Rust)
    - P448 (Fiat-Rust, mul only)
    - Poly1305 (Fiat-Rust)
    - Secp256k1-Dettman (Fiat-Rust)
    - Secp256k1 (Rust-EC)
    - BLS12 (Fiat-Rust, mul only, usize)
    - Curve25519 (Fiat-C)
    - P448 (Fiat-C)
    - Poly1305 (Fiat-C)
    - Secp256k1-Dettman (Fiat-C)
    - OpenSSL Curve25519 fe51 (51-bit field element representation)

## How It Works

### Enhanced Methodology (Recommended)

The enhanced measurement system addresses all academic reviewer concerns about microbenchmarking:

1.  **Environment Setup**: Automated CPU core pinning, frequency control, and noise reduction
2.  **Dynamic Batch Sizing**: CryptOpt's 10,000 cycle goal for consistent measurement precision
3.  **Randomized Execution**: Fisher-Yates shuffled batch order to prevent systematic bias
4.  **Multi-layered Warm-up**: Global, calibration, and targeted warm-up phases
5.  **Statistical Validation**: Coefficient of variation tracking and quality assessment
6.  **Median-of-Medians**: Multiple independent runs for robust final estimates

### Legacy Methodology (Basic)

The original tool performs simpler measurements:

1.  **Generate Random Inputs**: Creates appropriately sized random field elements within loose bounds.
2.  **Measure Execution Time**: Fixed batch size (200) sequential execution measurements
3.  **Calculate Median Performance**: Basic median calculation without quality validation
4.  **Repeat Measurements**: Simple repetition without statistical robustness checks
5.  **Compare Performance**: Basic percentage difference calculation

### Addressing Reviewer Concerns

The enhanced methodology specifically addresses academic review concerns:

| Reviewer Concern | Our Solution |
|------------------|--------------|
| **CPU core pinning** | ✅ Automated `taskset` core isolation |
| **Turbo Boost/frequency scaling** | ✅ Performance governor + frequency fixing |
| **SMT/ASLR control** | ✅ Optional disabling with user choice |
| **Iteration/batching strategies** | ✅ CryptOpt's R3-validation (31 batches, Fisher-Yates) |
| **Cycle measurement methods** | ✅ Memory barriers + RDTSC precision |
| **Warm-up procedures** | ✅ Multi-phase warm-up strategy |
| **Reproducibility** | ✅ Complete automation + documentation |
| **Performance benefit demonstration** | ✅ Comparison tool showing improvements |

## Usage

### Quick Start (Enhanced Methodology)

For publication-quality results that address all reviewer concerns:

```bash
# 1. Set up optimal benchmarking environment
chmod +x setup_benchmark_environment.sh
./setup_benchmark_environment.sh

# 2. Verify environment is ready
./verify_benchmark_environment.sh

# 3. Run enhanced measurements
ENHANCED_MEASUREMENT=1 ./run_benchmark_pinned.sh cargo run curve25519 mul 5

# 4. Restore system defaults when done
./restore_system_defaults.sh
```

### Methodology Comparison

To demonstrate the benefits of enhanced vs original methodology:

```bash
# Show systematic comparison of both approaches
chmod +x run_methodology_comparison.sh
./run_methodology_comparison.sh
```

This comparison script will show:
- **Measurement precision**: Dynamic vs fixed batch sizing
- **Bias reduction**: Randomized vs sequential execution
- **Statistical robustness**: Median-of-medians vs single measurements
- **Quality assessment**: CV tracking vs no validation

### Build the Project

The `build.rs` script compiles the necessary assembly files (`.asm`) into object files (`.o`) and archives them (`.a`). Cargo then links these archives.

```bash
cargo build
```

### Run Benchmarks

Execute the benchmark using `cargo run`, specifying the curve name, operation, and optionally, the number of times to repeat the median-of-medians measurement.

```bash
cargo run <curve_name> <operation> [repeat_count]
```

**Arguments:**

*   `<curve_name>`: The name of the curve/implementation to benchmark. Available options:
    *   `curve25519`
    *   `curve25519_dalek`
    *   `p448`
    *   `poly1305`
    *   `secp256k1_dettman`
    *   `secp256k1_rust_ec`
    *   `bls12`
    *   `fiat_c_curve25519`
    *   `fiat_c_p448`
    *   `fiat_c_poly1305`
    *   `fiat_c_secp256k1_dettman`
    *   `openssl_curve25519`
*   `<operation>`: The operation to benchmark. Available options:
    *   `mul`
    *   `square` (Note: Not available for all curves, e.g., `p448`, `bls12`)
*   `[repeat_count]` (Optional): The number of times to run the full median-of-medians measurement process. Defaults to 1.

**Example:**

```bash
# Benchmark Curve25519 multiplication, run the measurement process 5 times
cargo run curve25519 mul 5

# Benchmark Fiat-C P448 squaring (default 1 repeat)
cargo run fiat_c_p448 square
```

## Assembly Format Conversion Tool

The project includes a Python script `asm-cleaner2.py` that converts assembly files from AT&T syntax (GAS format) to NASM format. This tool is essential when integrating assembly code from sources that output AT&T syntax, such as LLVM or hand-optimized assembly from OpenSSL.

### Location

The script is located at: `src/asm-cleaner2.py`

### Usage

```bash
python3 src/asm-cleaner2.py <input_asm_file> <output_asm_file>
```

**Arguments:**
- `<input_asm_file>`: Path to the input assembly file in AT&T syntax
- `<output_asm_file>`: Path where the converted NASM format file will be saved

### Key Transformations

The script performs the following conversions:

1. **Register Prefixes**: Removes `%` prefix from registers (e.g., `%rax` → `rax`)
2. **Immediate Values**: Removes `$` prefix from immediate values (e.g., `$19` → `19`)
3. **Instruction Suffixes**: Removes size suffixes from instructions (e.g., `movq` → `mov`, `addl` → `add`)
4. **Memory Operands**: Converts AT&T style `offset(base,index,scale)` to NASM style `[base+index*scale+offset]`
5. **Operand Order**: Swaps operands from AT&T order (source, destination) to Intel order (destination, source)
6. **Directives**: Converts directives (e.g., `.globl` → `global`, `.align` → `ALIGN`)
7. **Local Labels**: Converts local labels to use function prefix (e.g., `.Lreduce51` → `function.Lreduce51`)
8. **Special Instructions**: Handles special cases like 3-operand `imul` instructions
9. **NASM Header**: Adds required NASM header with `default rel` and section declarations
10. **Function Naming**: Can append `_nasm` suffix to function names when needed for linking

### Example: Converting OpenSSL Hand-Optimized Assembly

To convert OpenSSL's hand-optimized curve25519 assembly files:

```bash
# Convert multiplication assembly
python3 src/asm-cleaner2.py \
    src/c/openssl-curve25519/hand-optimised/mul/hand_optimised_x86_64_mul.asm \
    src/c/openssl-curve25519/hand-optimised-nasm/mul/hand_optimised_x86_64_mul_nasm.asm

# Convert square assembly
python3 src/asm-cleaner2.py \
    src/c/openssl-curve25519/hand-optimised/square/hand_optimised_x86_64_square.asm \
    src/c/openssl-curve25519/hand-optimised-nasm/square/hand_optimised_x86_64_square_nasm.asm
```

### When to Use This Tool

Use `asm-cleaner2.py` when:
- Integrating assembly code that uses AT&T syntax
- Converting LLVM output (which typically uses GAS format) to NASM
- Adapting hand-written assembly from projects like OpenSSL
- The assembly file uses syntax incompatible with NASM

The converted files can then be compiled with NASM and linked into the project as part of the build process managed by `build.rs`.

## OpenSSL Curve25519 fe51 Support

The project includes support for OpenSSL's Curve25519 implementation using the fe51 (51-bit field element) representation. This provides an industry-standard baseline for comparing the performance of other implementations.

### What is fe51?

The fe51 representation uses a 51-bit radix to represent field elements in Curve25519. This means:
- Field elements are represented as 5 limbs of 51 bits each (stored in 64-bit words)
- This representation allows for efficient arithmetic on 64-bit processors
- OpenSSL's implementation includes both compiler-generated and hand-optimized assembly versions

### Available OpenSSL Implementations

The project benchmarks multiple variants of OpenSSL's fe51 implementation:

1. **LLVM-compiled versions**:
   - `open_ssl_curve25519_fe51_mul` - GAS format multiplication
   - `open_ssl_curve25519_fe51_mul_nasm` - NASM format multiplication
   - `open_ssl_curve25519_fe51_square` - GAS format squaring
   - `open_ssl_curve25519_fe51_square_nasm` - NASM format squaring

2. **Hand-optimized assembly versions**:
   - `open_ssl_curve25519_hand_optmised_fe51_mul` - Hand-optimized multiplication (converted from AT&T syntax)
   - `open_ssl_curve25519_hand_optmised_fe51_mul_nasm` - NASM version of hand-optimized multiplication
   - `open_ssl_curve25519_hand_optmised_fe51_square` - Hand-optimized squaring (converted from AT&T syntax)
   - `open_ssl_curve25519_hand_optmised_fe51_square_nasm` - NASM version of hand-optimized squaring

3. **CryptOpt-optimized version**:
   - `open_ssl_curve25519_fe51_mul_CryptOpt` - CryptOpt-optimized multiplication
   - `open_ssl_curve25519_fe51_square_CryptOpt` - CryptOpt-optimized squaring

### Running OpenSSL Benchmarks

To benchmark OpenSSL's Curve25519 fe51 implementation:

```bash
# Benchmark OpenSSL Curve25519 multiplication
cargo run openssl_curve25519 mul

# Benchmark OpenSSL Curve25519 squaring with 5 repetitions
cargo run openssl_curve25519 square 5
```

### Performance Comparison

The OpenSSL fe51 implementation serves as an excellent baseline because:
- It's widely deployed in production systems
- The hand-optimized assembly has been carefully tuned by cryptography experts
- It uses the same 51-bit representation as many other high-performance implementations

This allows for meaningful comparisons between:
- OpenSSL's hand-optimized assembly vs. compiler-generated code
- OpenSSL's implementation vs. Fiat-generated code
- OpenSSL's implementation vs. CryptOpt optimizations

The benchmarking results will show the cycle counts for each variant, helping identify which optimizations provide the most benefit.

